import google.generativeai as genai

class Chatbot:
    def __init__(self, config, database, embeddings):
        """
        Inicializa o Chatbot com configura칞칫es, banco de dados e modelo de embeddings.

        Par칙metros:
        - config: Inst칙ncia da classe Config, contendo API_KEY, banco de dados e embeddings.
        - database: Inst칙ncia da classe Database para gerenciar contexto do usu치rio.
        - embeddings: Inst칙ncia da classe Embeddings para gerar vetores sem칙nticos.
        """
        self.config = config
        self.database = database
        self.embeddings = embeddings
        self.model = genai.GenerativeModel("gemini-2.0-flash")  # 游댠 Corre칞칚o aqui!

    def get_response(self, user_message, user_id="default"):
        """
        Processa a mensagem do usu치rio, busca contexto e gera uma resposta.

        Par칙metros:
        - user_message: Mensagem enviada pelo usu치rio.
        - user_id: Identificador do usu치rio (para gerenciar contexto).

        Retorna:
        - Resposta gerada pelo chatbot.
        """
        # Obt칠m o contexto armazenado do usu치rio
        context = self.database.get_context(user_id)

        # Gera embeddings da mensagem do usu치rio
        user_embedding = self.embeddings.encode(user_message)

        # Se houver contexto armazenado, concatena para gerar uma melhor resposta
        if context:
            prompt = f"Hist칩rico: {context}\nUsu치rio: {user_message}\nChatbot:"
        else:
            prompt = f"Usu치rio: {user_message}\nChatbot:"

        # Chama a API Gemini AI para gerar uma resposta
        response = self._generate_response(prompt)

        # Atualiza o contexto armazenado no banco de dados
        new_context = f"{context} {user_message} {response}" if context else f"{user_message} {response}"
        self.database.add_context(user_id, new_context)

        return response

    def _generate_response(self, prompt):
        """
        Usa o Gemini AI para gerar uma resposta baseada no prompt.

        Par칙metros:
        - prompt: Texto de entrada com o contexto da conversa.

        Retorna:
        - Resposta gerada pelo modelo AI.
        """
        try:
            response = self.model.generate_content(prompt)  # 游댠 Corre칞칚o aqui!
            return response.text.strip() if response and response.text else "N칚o entendi, pode reformular?"
        except Exception as e:
            return f"Erro ao gerar resposta: {str(e)}"
